swinir(
  (conv_first): Conv2d(1, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (patch_embed): PatchEmbed(
    (norm): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
  )
  (patch_unembed): PatchUnEmbed()
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): RSTB(
      (residual_group): BasicLayer(
        dim=90, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.006)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.012)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.018)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.024)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.029)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (1): RSTB(
      (residual_group): BasicLayer(
        dim=90, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.035)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.041)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.047)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.053)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.059)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.065)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (2): RSTB(
      (residual_group): BasicLayer(
        dim=90, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.071)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.076)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.082)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.088)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.094)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.100)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
  )
  (norm): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
  (conv_after_body): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (uplayers): ModuleList()
  (conv_before_upsample): Sequential(
    (0): Conv2d(90, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
  )
  (upsample): Upsample(
    (0): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=2)
  )
  (conv_last): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)
swinir(
  (conv_first): Conv2d(1, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (patch_embed): PatchEmbed(
    (norm): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
  )
  (patch_unembed): PatchUnEmbed()
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): RSTB(
      (residual_group): BasicLayer(
        dim=90, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.006)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.012)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.018)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.024)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.029)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (1): RSTB(
      (residual_group): BasicLayer(
        dim=90, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.035)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.041)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.047)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.053)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.059)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.065)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (2): RSTB(
      (residual_group): BasicLayer(
        dim=90, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.071)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.076)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.082)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.088)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.094)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.100)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
  )
  (norm): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
  (conv_after_body): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (uplayers): ModuleList()
  (conv_before_upsample): Sequential(
    (0): Conv2d(90, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
  )
  (upsample): Upsample(
    (0): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=2)
  )
  (conv_last): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)
swinir(
  (conv_first): Conv2d(1, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (patch_embed): PatchEmbed(
    (norm): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
  )
  (patch_unembed): PatchUnEmbed()
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): RSTB(
      (residual_group): BasicLayer(
        dim=90, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.006)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.012)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.018)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.024)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.029)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (1): RSTB(
      (residual_group): BasicLayer(
        dim=90, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.035)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.041)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.047)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.053)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.059)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.065)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (2): RSTB(
      (residual_group): BasicLayer(
        dim=90, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.071)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.076)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.082)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.088)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.094)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.100)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
  )
  (norm): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
  (conv_after_body): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (uplayers): ModuleList()
  (conv_before_upsample): Sequential(
    (0): Conv2d(90, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
  )
  (upsample): Upsample(
    (0): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=2)
  )
  (conv_last): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)
swinir(
  (conv_first): Conv2d(1, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (patch_embed): PatchEmbed(
    (norm): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
  )
  (patch_unembed): PatchUnEmbed()
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): RSTB(
      (residual_group): BasicLayer(
        dim=90, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.006)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.012)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.018)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.024)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.029)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (1): RSTB(
      (residual_group): BasicLayer(
        dim=90, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.035)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.041)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.047)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.053)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.059)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.065)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (2): RSTB(
      (residual_group): BasicLayer(
        dim=90, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.071)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.076)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.082)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.088)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.094)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=90, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2.0
            (norm1): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=90, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=90, out_features=270, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=90, out_features=90, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.100)
            (norm2): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=90, out_features=180, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=180, out_features=90, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
  )
  (norm): LayerNorm((90,), eps=1e-05, elementwise_affine=True)
  (conv_after_body): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (uplayers): ModuleList()
  (conv_before_upsample): Sequential(
    (0): Conv2d(90, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
  )
  (upsample): Upsample(
    (0): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=2)
  )
  (conv_last): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)
